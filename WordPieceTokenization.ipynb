{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from collections import defaultdict, OrderedDict\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('swag', 'regular', split='train[:1000]')\n",
    "corpus = dataset['ending0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: ['##!', \"##'\", '##7', '##:', '##;', '##a', '##b', '##c', '##d', '##e', '##f', '##g', '##h', '##i', '##j', '##k', '##l', '##m', '##n', '##o', '##p', '##q', '##r', '##s', '##t', '##u', '##v', '##w', '##x', '##y', '##z', \"'\", ',', '-', '.', '1', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z']\n",
      "vocab_size:  61\n"
     ]
    }
   ],
   "source": [
    "words_freq = Counter(re.sub(r\"([.,])\", r\" \\1 \", ' '.join(corpus)).split())\n",
    "vocab = []\n",
    "\n",
    "for word in words_freq:\n",
    "    if word[0] not in vocab:\n",
    "        vocab.append(word[0])\n",
    "    \n",
    "    for c in word[1:]:\n",
    "        if not f\"##{c}\" in vocab:\n",
    "            vocab.append(f\"##{c}\")\n",
    "\n",
    "vocab_itos = dict(zip(range(len(vocab)), vocab))\n",
    "vocab_stoi = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "print(\"vocab:\", sorted(vocab))\n",
    "print(\"vocab_size: \", len(vocab))\n",
    "\n",
    "splits = {\n",
    "    word: [f\"##{item}\" if i!=0 else item for i, item in enumerate(list(word))]\n",
    "    for word in words_freq\n",
    "}\n",
    "\n",
    "def make_pair(l: list):\n",
    "    \"\"\"\n",
    "    creates pairs for the given list\n",
    "    \"\"\"\n",
    "    return [(l[i], l[i+1]) for i in range(len(l)-1)]\n",
    "\n",
    "def compute_score(pairs_count_, letter_counts_):\n",
    "    scores = defaultdict(float)\n",
    "\n",
    "    for k, v in pairs_count_.items():\n",
    "        letter1_count = letter_counts_[k[0]]\n",
    "        letter2_count = letter_counts_[k[1]]\n",
    "        pair_count = v\n",
    "        score = pair_count / (letter1_count * letter2_count)\n",
    "        scores[k] = score\n",
    "    return scores\n",
    "\n",
    "def merge_pair(a, b):\n",
    "    new_splits = defaultdict(list)\n",
    "    new_tokens = set()\n",
    "\n",
    "    for word, split in splits.items():\n",
    "        new_split = split\n",
    "        new_splits[word] = new_split\n",
    "        for i in range(len(split)-1):\n",
    "            if split[i] == a and split[i+1] == b:\n",
    "                merge = a + b[2:] if b[:2] == \"##\" else a + b\n",
    "                new_split = split[:i] + [merge] + split[i+2:]\n",
    "                new_tokens.add(merge)\n",
    "        new_splits[word] = new_split\n",
    "    return (new_splits, new_tokens)\n",
    "\n",
    "def encode_word(word):\n",
    "    tokens = []\n",
    "    found = True\n",
    "    while word != \"##\" and found:\n",
    "        found = False\n",
    "        for i in range(len(word), -1, -1):\n",
    "            if word[:i] in vocab_stoi:\n",
    "                tokens.append(word[:i])\n",
    "                word = f\"##{word[i:]}\"\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            tokens.append(\"UNK\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 1000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "max_iters = 1000\n",
    "\n",
    "while True:\n",
    "    letter_counts = Counter(sum([splits[w] * c for w, c in words_freq.items()], []))\n",
    "    pair_counts = Counter(sum([make_pair(splits[w]) * c for w, c in words_freq.items()], []))\n",
    "\n",
    "    scores = compute_score(pair_counts, letter_counts)\n",
    "    if not scores or i == max_iters:\n",
    "        break\n",
    "    best_pair = max(scores.items(), key=lambda item: item[1])\n",
    "\n",
    "    new_splits, new_tokens = merge_pair(*best_pair[0])\n",
    "    splits = new_splits\n",
    "    vocab.extend(new_tokens)\n",
    "    i += 1\n",
    "\n",
    "print(f\"Total iterations: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_itos = dict(zip(range(len(vocab)), vocab))\n",
    "vocab_stoi = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perform      : ['p', '##e', '##r', '##f', '##o', '##r', '##m']\n",
      "cartwheels   : ['cartwh', '##e', '##e', '##l', '##s']\n",
      ",            : [',']\n",
      "then         : ['th', '##e', '##n']\n",
      "fly          : ['f', '##l', '##y']\n",
      "in           : ['in']\n",
      "the          : ['th', '##e']\n",
      "water        : ['wat', '##e', '##r']\n",
      "and          : ['and']\n",
      "shoot        : ['sh', '##o', '##o', '##t']\n",
      "another      : ['a', '##n', '##o', '##th', '##e', '##r']\n",
      ".            : ['.']\n",
      "takes        : ['tak', '##e', '##s']\n",
      "off          : ['off']\n",
      "another      : ['a', '##n', '##o', '##th', '##e', '##r']\n",
      "mixture      : ['mixtur', '##e']\n",
      "and          : ['and']\n",
      "flashes      : ['flash', '##e', '##s']\n",
      "radar        : ['r', '##a', '##d', '##a', '##r']\n",
      "at           : ['a', '##t']\n",
      "the          : ['th', '##e']\n",
      "end          : ['end']\n",
      "of           : ['of']\n",
      "the          : ['th', '##e']\n",
      "glass        : ['g', '##l', '##a', '##s', '##s']\n",
      ".            : ['.']\n",
      "take         : ['tak', '##e']\n",
      "their        : ['th', '##e', '##i', '##r']\n",
      "turns        : ['turns']\n",
      "volting      : ['v', '##o', '##l', '##t', '##ing']\n",
      "over         : ['ov', '##e', '##r']\n",
      "the          : ['th', '##e']\n",
      "bar          : ['b', '##a', '##r']\n",
      "and          : ['and']\n",
      "landing      : ['landing']\n",
      "on           : ['on']\n",
      "a            : ['a']\n",
      "mat          : ['m', '##a', '##t']\n",
      ".            : ['.']\n",
      "runs         : ['runs']\n",
      "around       : ['around']\n",
      "and          : ['and']\n",
      "jumps        : ['jump', '##s']\n",
      "down         : ['down']\n",
      "to           : ['to']\n",
      "perform      : ['p', '##e', '##r', '##f', '##o', '##r', '##m']\n",
      "a            : ['a']\n",
      "jumps        : ['jump', '##s']\n",
      "in           : ['in']\n",
      "the          : ['th', '##e']\n",
      "end          : ['end']\n",
      ".            : ['.']\n",
      "is           : ['is']\n",
      "seen         : ['s', '##e', '##e', '##n']\n",
      "sticking     : ['s', '##t', '##i', '##ck', '##ing']\n",
      "at           : ['a', '##t']\n",
      "the          : ['th', '##e']\n",
      "bottom       : ['b', '##o', '##t', '##t', '##o', '##m']\n",
      "for          : ['f', '##o', '##r']\n",
      "hopscotch    : ['h', '##o', '##p', '##s', '##c', '##o', '##tch']\n",
      ".            : ['.']\n",
      "shows        : ['shows']\n",
      "the          : ['th', '##e']\n",
      "reading      : ['r', '##e', '##a', '##d', '##ing']\n",
      "bottles      : ['b', '##o', '##t', '##t', '##l', '##e', '##s']\n",
      ".            : ['.']\n",
      "flips        : ['f', '##l', '##i', '##p', '##s']\n",
      "past         : ['p', '##a', '##s', '##t']\n",
      "the          : ['th', '##e']\n",
      "other        : ['oth', '##e', '##r']\n",
      "and          : ['and']\n",
      "hugs         : ['h', '##u', '##g', '##s']\n",
      "her          : ['h', '##e', '##r']\n",
      ".            : ['.']\n",
      "someone      : ['s', '##o', '##m', '##e', '##o', '##n', '##e']\n",
      "grabs        : ['g', '##r', '##a', '##b', '##s']\n",
      "a            : ['a']\n",
      "handheld     : ['handh', '##e', '##l', '##d']\n",
      "pole         : ['p', '##o', '##l', '##e']\n",
      ",            : [',']\n",
      "someone      : ['s', '##o', '##m', '##e', '##o', '##n', '##e']\n",
      "puts         : ['puts']\n",
      "a            : ['a']\n",
      "split        : ['s', '##p', '##l', '##i', '##t']\n",
      "glove        : ['g', '##l', '##o', '##v', '##e']\n",
      "off          : ['off']\n",
      "the          : ['th', '##e']\n",
      "table        : ['tabl', '##e']\n",
      "and          : ['and']\n",
      "hugs         : ['h', '##u', '##g', '##s']\n",
      "her          : ['h', '##e', '##r']\n",
      ".            : ['.']\n",
      "turns        : ['turns']\n",
      "around       : ['around']\n",
      ",            : [',']\n",
      "smiling      : ['s', '##m', '##i', '##l', '##ing']\n",
      "perfunctorily: ['p', '##e', '##r', '##f', '##u', '##n', '##c', '##t', '##o', '##r', '##i', '##l', '##y']\n",
      ".            : ['.']\n",
      "stares       : ['s', '##t', '##a', '##r', '##e', '##s']\n",
      ",            : [',']\n",
      "dazed        : ['daz', '##e', '##d']\n",
      ",            : [',']\n",
      "with         : ['with']\n",
      "a            : ['a']\n",
      "large        : ['l', '##a', '##r', '##g', '##e']\n",
      "chinese      : ['ch', '##i', '##n', '##e', '##s', '##e']\n",
      "lady         : ['l', '##a', '##d', '##y']\n",
      ".            : ['.']\n"
     ]
    }
   ],
   "source": [
    "# let's encode some random words\n",
    "start = randint(0, len(corpus)-10)\n",
    "end = start + 10\n",
    "words = re.sub(r\"([.,])\", r\" \\1 \", ' '.join(corpus[start:end])).split()\n",
    "max_word_len = len(max(words, key=len))\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word:<{max_word_len}}: {encode_word(word)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
